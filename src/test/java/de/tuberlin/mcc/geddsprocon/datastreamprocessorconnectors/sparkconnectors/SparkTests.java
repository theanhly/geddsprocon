package de.tuberlin.mcc.geddsprocon.datastreamprocessorconnectors.sparkconnectors;

import de.tuberlin.mcc.geddsprocon.DSPConnectorFactory;
import de.tuberlin.mcc.geddsprocon.DSPConnectorConfig;
import de.tuberlin.mcc.geddsprocon.datastreamprocessorconnectors.SocketPool;
import org.apache.commons.lang.SerializationUtils;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.*;
import org.apache.spark.serializer.KryoSerializer;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.*;
import org.apache.spark.streaming.receiver.Receiver;
import org.junit.Test;
import org.zeromq.ZMQ;
import scala.Tuple2;

import java.text.SimpleDateFormat;
import java.util.Arrays;
import java.util.Date;

public class SparkTests {
    //
    // NEW PULL BASED APPROACH
    //

    // ======== Additional addresses test with new approach =======
    @Test
    public void pullBasedApproachSink1() {
        try {
            ZMQ.Context context = ZMQ.context(1);

            //  Socket to talk to server
            System.out.println("Connecting to hello world server…");

            ZMQ.Socket sender = context.socket(ZMQ.PUSH);
            sender.connect("tcp://localhost:9655");

            String testString =  "a b c d e f g h i j k l m n o p q r s t u v w x y z";

            System.out.println("Sending: " + testString);
            sender.send(SerializationUtils.serialize(testString), 0);

            SparkConf sparkConf = new SparkConf().setAppName("JavaCustomReceiver").setMaster("local[*]").set("spark.executor.memory","1g").set("spark.serializer", KryoSerializer.class.getName());
            JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(5000));

            // Create an input stream with the custom receiver on target ip:port and count the
            // words in input stream of \n delimited text (eg. generated by 'nc')
            JavaReceiverInputDStream<String> lines =
                    ssc.receiverStream((Receiver)new DSPConnectorFactory<>().createSourceConnector(new DSPConnectorConfig.Builder("localhost", 9655)
                            .withDSP("spark")
                            .withSocketType(SocketPool.SocketType.PULL)
                            .build()));

            //      Split each line into words
            JavaDStream<String> words = lines.flatMap(
                    (FlatMapFunction<String, String>) x -> Arrays.asList(x.split(" ")).iterator()
            );


            //      Count each word in each batch
            JavaPairDStream<String, Integer> pairs = words.mapToPair(
                    (PairFunction<String, String, Integer>) s -> new Tuple2<>(s, 1)
            );

            pairs.foreachRDD((VoidFunction)new DSPConnectorFactory<>().createSinkConnector(new DSPConnectorConfig.Builder("localhost", 9666)
                    .withDSP("spark")
                    .withTimeout(10000)
                    .build()));

            //wordCounts.print();
            ssc.start();
            ssc.awaitTermination();
        } catch(Exception ex) {
            System.err.println(ex.toString() + ex.getStackTrace());
        }
    }

    @Test
    public void pullBasedApproachSource1() {
        try {

            SparkConf sparkConf = new SparkConf().setAppName("JavaCustomReceiver").setMaster("local[*]").set("spark.executor.memory","1g").set("spark.serializer", KryoSerializer.class.getName());
            JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(5000));

            // Create an input stream with the custom receiver on target ip:port and count the
            // words in input stream of \n delimited text (eg. generated by 'nc')
            JavaReceiverInputDStream<Tuple2<String, Integer>> tuples = ssc.receiverStream((Receiver)new DSPConnectorFactory<>().createSourceConnector(new DSPConnectorConfig.Builder()
                    .withRequestAddress("localhost", 9656, DSPConnectorFactory.ConnectorType.PRIMARY)
                    .withDSP("spark")
                    .build()));

            //      Split each line into words
            //JavaDStream<String> words = lines.flatMap(
            //       (FlatMapFunction<String, String>) x -> Arrays.asList(x.split(" ")).iterator()
            //);

            //words.foreachRDD((VoidFunction)new DSPConnectorFactory<>().createSinkConnector(DSPConnectorFactory.DataStreamProcessors.SPARK, "localhost", 6556));

            //      Count each word in each batch
            JavaPairDStream<String, Integer> pairs = tuples.mapToPair(
                    (PairFunction<Tuple2<String, Integer>, String, Integer>) s -> new Tuple2<>(s._1, s._2)
            );


            //      Cumulate the sum from each batch
            JavaPairDStream<String, Integer> wordCounts = pairs.reduceByKey(
                    (Function2<Integer, Integer, Integer>) (i1, i2) -> i1 + i2
            );

            //wordCounts.foreachRDD((VoidFunction)new DSPConnectorFactory<>().createSinkConnector(DSPConnectorFactory.DataStreamProcessors.SPARK, "localhost", 6556));

            wordCounts.print();
            ssc.start();
            ssc.awaitTermination();
        } catch(Exception ex) {
            System.err.println(ex.toString() + ex.getStackTrace());
        }
    }
    // ======== Test end =======


    // Checkpointing test
    @Test
    public void sendData() {
        ZMQ.Context context = ZMQ.context(1);

        //  Socket to talk to server
        System.out.println("Connecting to hello world server…");

        ZMQ.Socket sender = context.socket(ZMQ.PUSH);
        sender.setSndHWM(1);
        sender.connect("tcp://localhost:9655");

        String testString =  "a b c d e f g h i j k l m n o p q r s t u v w x y z";

        System.out.println("Sending: " + testString);
        sender.send(SerializationUtils.serialize(testString));
    }

    private JavaStreamingContext createSCC(String checkpointDirectory) {
        SparkConf sparkConf = new SparkConf().setAppName("JavaCustomReceiver").setMaster("local[*]").set("spark.executor.memory","1g").set("spark.serializer", KryoSerializer.class.getName());
        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(5000));
        ssc.checkpoint(checkpointDirectory);
        // Create an input stream with the custom receiver on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        JavaReceiverInputDStream<String> lines =
                ssc.receiverStream((Receiver)new DSPConnectorFactory<>().createSourceConnector(new DSPConnectorConfig.Builder("localhost", 9655)
                        .withDSP("spark")
                        .withSocketType(SocketPool.SocketType.PULL)
                        .build()));

        //      Split each line into words
        JavaDStream<String> words = lines.flatMap(
                (FlatMapFunction<String, String>) x -> Arrays.asList(x.split(" ")).iterator()
        );


        //      Count each word in each batch
        JavaPairDStream<String, Integer> pairs = words.mapToPair(
                (PairFunction<String, String, Integer>) s -> new Tuple2<>(s, 1)
        );

        pairs.foreachRDD((VoidFunction)new DSPConnectorFactory<>().createSinkConnector(new DSPConnectorConfig.Builder("localhost", 9666)
                .withDSP("spark")
                .withHWM(20)
                .withBufferConnectorString("buffer-test")
                .withTimeout(10000)
                .build()));

        //wordCounts.print();
        return ssc;
    }

    @Test
    public void checkpointingTest() {
        try {
            String checkpointDirectory = "/home/theanhly/Schreibtisch/checkpointing_test";

            // Function to create JavaStreamingContext without any output operations
            // (used to detect the new context)
            Function0<JavaStreamingContext> createContextFunc =
                    () -> createSCC(checkpointDirectory);

            JavaStreamingContext ssc =
                    JavaStreamingContext.getOrCreate(checkpointDirectory, createContextFunc);

            ssc.start();
            ssc.awaitTermination();
        } catch(Exception ex) {
            System.err.println(ex.toString() + ex.getStackTrace());
        }
    }
}
